{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from library import terms_to_graph, compute_node_centrality, print_top10, print_bot10\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2803, 2)\n",
      "(1396, 2)\n",
      "first five rows of training data:\n",
      "         0                                                  1\n",
      "0  student  brian comput scienc depart univers wisconsin d...\n",
      "1  student  denni swanson web page mail pop uki offic hour...\n",
      "2  faculty  russel impagliazzo depart comput scienc engin ...\n",
      "3  student  dave phd student depart comput scienc univers ...\n",
      "4  project  center lifelong learn design univers colorado ...\n",
      "first five rows of testing data:\n",
      "         0                                                  1\n",
      "0  student  eric homepag eric wei tsinghua physic fudan genet\n",
      "1   course  comput system perform evalu model new sept ass...\n",
      "2  student  home page comput scienc grad student ucsd work...\n",
      "3  student  toni web page toni face thing call toni studen...\n",
      "4   course  ec advanc comput architectur credit parallel a...\n",
      "removing 29 documents from training set\n",
      "(2774, 2)\n",
      "removing 20 documents from test set\n",
      "(1376, 2)\n",
      "number of observations per class:\n",
      "faculty : 744\n",
      "student : 1075\n",
      "project : 335\n",
      "course : 620\n",
      "storing terms from training documents as list of lists\n",
      "storing terms from test documents as list of lists\n",
      "min, max and average number of terms per document: 4 20628 134.09084354722424\n",
      "0 terms processed\n",
      "1000 terms processed\n",
      "2000 terms processed\n",
      "3000 terms processed\n",
      "4000 terms processed\n",
      "5000 terms processed\n",
      "6000 terms processed\n",
      "7000 terms processed\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# data loading and preprocessing #\n",
    "##################################\n",
    "\n",
    "path_to_data = \"../data\"\n",
    "\n",
    "train = pd.read_csv(path_to_data + \"/webkb-train-stemmed.txt\", header=None, delimiter=\"\\t\")\n",
    "print(train.shape)\n",
    "\n",
    "test = pd.read_csv(path_to_data + \"/webkb-test-stemmed.txt\", header=None, delimiter=\"\\t\")\n",
    "print(test.shape)\n",
    "\n",
    "# inspect head of data frames\n",
    "print(\"first five rows of training data:\")\n",
    "print(train.iloc[:5,:])\n",
    "\n",
    "print(\"first five rows of testing data:\")\n",
    "print(test.iloc[:5,:])\n",
    "\n",
    "# get index of empty (nan) and less than four words documents (for which a graph cannot be built)\n",
    "index_remove = [i for i in range(len(train.iloc[:,1])) if (train.iloc[i,1]!=train.iloc[i,1]) or ((train.iloc[i,1]==train.iloc[i,1])and(len(train.iloc[i,1].split(\" \"))<4))]\n",
    "\n",
    "# remove those documents\n",
    "print(\"removing\", len(index_remove), \"documents from training set\")\n",
    "train = train.drop(train.index[index_remove])\n",
    "print(train.shape)\n",
    "\n",
    "# repeat above steps for test set\n",
    "index_remove = [i for i in range(len(test.iloc[:,1])) if (test.iloc[i,1]!=test.iloc[i,1]) or ((test.iloc[i,1]==test.iloc[i,1])and(len(test.iloc[i,1].split(\" \"))<4))]\n",
    "print(\"removing\", len(index_remove), \"documents from test set\")\n",
    "test = test.drop(test.index[index_remove])\n",
    "print(test.shape)\n",
    "\n",
    "labels = train.iloc[:,0]\n",
    "unique_labels = list(set(labels))\n",
    "\n",
    "truth = test.iloc[:,0]\n",
    "unique_truth = list(set(truth))\n",
    "\n",
    "print(\"number of observations per class:\")\n",
    "for label in unique_labels:\n",
    "    print(label, \":\", len([temp for temp in labels if temp==label]))\n",
    "\n",
    "print(\"storing terms from training documents as list of lists\")\n",
    "terms_by_doc = [document.split(\" \") for document in train.iloc[:,1]]\n",
    "n_terms_per_doc = [len(terms) for terms in terms_by_doc]\n",
    "\n",
    "print(\"storing terms from test documents as list of lists\")\n",
    "terms_by_doc_test = [document.split(\" \") for document in test.iloc[:,1]]\n",
    "\n",
    "print(\"min, max and average number of terms per document:\", min(n_terms_per_doc), max(n_terms_per_doc), sum(n_terms_per_doc)/len(n_terms_per_doc))\n",
    "\n",
    "# store all terms in list\n",
    "all_terms = [terms for sublist in terms_by_doc for terms in sublist] # flatten 'terms_by_doc'\n",
    "\n",
    "# compute average number of terms\n",
    "avg_len = sum(n_terms_per_doc)/len(n_terms_per_doc)\n",
    "\n",
    "# unique terms\n",
    "all_unique_terms = list(set(all_terms)) # get unique elements (the vocabulary) from 'all_terms'\n",
    "\n",
    "# store IDF values in dictionary\n",
    "terms_by_doc_sets = [set(elt) for elt in terms_by_doc]\n",
    "n_doc = len(labels)\n",
    "idf = dict(zip(all_unique_terms,[0]*len(all_unique_terms)))\n",
    "\n",
    "for counter,unique_term in enumerate(list(idf.keys())):\n",
    "    # compute number of documents in which 'unique_term' appears\n",
    "    df = sum([unique_term in terms for terms in terms_by_doc_sets]) # iterate over 'terms_by_doc_sets' and test for the presence of 'unique_term'. Sum the booleans to get the counts\n",
    "    # idf\n",
    "    idf[unique_term] = math.log10(n_doc/(1+df))\n",
    "    if counter % 1e3 == 0:\n",
    "        print(counter, \"terms processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a graph-of-words for the collection\n",
      "True\n",
      "creating a graph-of-words for each training document\n",
      "True\n",
      "True\n",
      "computing vector representations of each training document\n",
      "0 documents processed\n",
      "1000 documents processed\n",
      "2000 documents processed\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# computing features for the training set #\n",
    "###########################################\n",
    "\n",
    "w = 3 # sliding window size\n",
    "\n",
    "print(\"creating a graph-of-words for the collection\")\n",
    "\n",
    "c_g = terms_to_graph([all_unique_terms],w,overspanning=False)\n",
    "\n",
    "# sanity check (should return True)\n",
    "print(len(all_unique_terms) == len(c_g.vs))\n",
    "\n",
    "print(\"creating a graph-of-words for each training document\")\n",
    "\n",
    "all_graphs = []\n",
    "for elt in terms_by_doc:\n",
    "    all_graphs.append(terms_to_graph([elt],w,overspanning=True))\n",
    "\n",
    "# sanity checks (should return True)\n",
    "print(len(terms_by_doc)==len(all_graphs))\n",
    "print(len(set(terms_by_doc[0]))==len(all_graphs[0].vs))\n",
    "\n",
    "print(\"computing vector representations of each training document\")\n",
    "\n",
    "b = 0.003\n",
    "\n",
    "features_degree = []\n",
    "features_w_degree = []\n",
    "features_closeness = []\n",
    "features_w_closeness = []\n",
    "features_twicw = [] # we try it only with unweighted degree\n",
    "features_tfidf = []\n",
    "\n",
    "len_all = len(all_unique_terms)\n",
    "collection_degrees = dict(zip(c_g.vs[\"name\"], c_g.degree())) # build a dict where the keys are the names of the nodes in the collection graph and the values are their unweighted degrees\n",
    "maxcol = max(list(collection_degrees.values()))\n",
    "\n",
    "for i, graph in enumerate(all_graphs):\n",
    "    \n",
    "    terms_in_doc = terms_by_doc[i]\n",
    "    doc_len = len(terms_in_doc)\n",
    "    \n",
    "    # returns node (0) name, (1) degree, (2) weighted degree, (3) closeness, (4) weighted closeness\n",
    "    my_metrics = compute_node_centrality(graph)\n",
    "    \n",
    "    feature_row_degree = [0]*len_all\n",
    "    feature_row_w_degree = [0]*len_all\n",
    "    feature_row_closeness = [0]*len_all\n",
    "    feature_row_w_closeness = [0]*len_all\n",
    "    feature_row_twicw = [0]*len_all\n",
    "    feature_row_tfidf = [0]*len_all\n",
    "    \n",
    "    # iterate over the unique terms contained by the doc (for all the other columns, the values will remain at zero)\n",
    "    for term in list(set(terms_in_doc)):\n",
    "        \n",
    "        index = all_unique_terms.index(term)\n",
    "        idf_term = idf[term]\n",
    "        denominator = (1-b+(b*(float(doc_len)/avg_len))) # equation 3 in the handout\n",
    "        metrics_term = [tuple[1:] for tuple in my_metrics if tuple[0]==term][0]\n",
    "\n",
    "        # store TW-IDF values\n",
    "        feature_row_degree[index] = (metrics_term[0]/denominator) * idf_term\n",
    "        feature_row_w_degree[index] = (metrics_term[1]/denominator) * idf_term\n",
    "        feature_row_closeness[index] = (metrics_term[2]/denominator) * idf_term\n",
    "        feature_row_w_closeness[index] = (metrics_term[3]/denominator) * idf_term\n",
    "        \n",
    "        # store TW-ICW values\n",
    "        feature_row_twicw[index] = (metrics_term[0]/denominator) * math.log10((maxcol+1)/collection_degrees[term]) \n",
    "        \n",
    "        # number of occurrences of word in document\n",
    "        tf = terms_in_doc.count(term)        \n",
    "        # store TF-IDF value\n",
    "        feature_row_tfidf[index] = ((1+math.log1p(1+math.log1p(tf)))/(1-0.2+(0.2*(float(doc_len)/avg_len)))) * idf_term\n",
    "    \n",
    "    features_degree.append(feature_row_degree)\n",
    "    features_w_degree.append(feature_row_w_degree)\n",
    "    features_closeness.append(feature_row_closeness)\n",
    "    features_w_closeness.append(feature_row_w_closeness)\n",
    "    features_twicw.append(feature_row_twicw)\n",
    "    features_tfidf.append(feature_row_tfidf)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        print (i, \"documents processed\")\n",
    "\n",
    "# convert list of lists into array\n",
    "# documents as rows, unique words (features) as columns\n",
    "training_set_degree = numpy.array(features_degree)\n",
    "training_set_w_degree = numpy.array(features_w_degree)\n",
    "training_set_closeness = numpy.array(features_closeness)\n",
    "training_set_w_closeness = numpy.array(features_w_closeness)\n",
    "training_set_tw_icw = numpy.array(features_twicw)\n",
    "training_set_tfidf = numpy.array(features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating a graph-of-words for each test document\n",
      "True\n",
      "True\n",
      "computing vector representations of each test document\n",
      "0 documents processed\n",
      "500 documents processed\n",
      "1000 documents processed\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# computing features for the test set #\n",
    "#######################################\n",
    "\n",
    "print(\"creating a graph-of-words for each test document\")\n",
    "\n",
    "all_graphs_test = []\n",
    "for elt in terms_by_doc_test:\n",
    "    all_graphs_test.append(terms_to_graph([elt],w,overspanning=True))\n",
    "\n",
    "# sanity checks (should return True)\n",
    "print(len(terms_by_doc_test)==len(all_graphs_test))\n",
    "print(len(set(terms_by_doc_test[0]))==len(all_graphs_test[0].vs))\n",
    "\n",
    "print(\"computing vector representations of each test document\")\n",
    "# ! each test document is represented in the training space only\n",
    "\n",
    "features_degree_test = []\n",
    "features_w_degree_test = []\n",
    "features_closeness_test = []\n",
    "features_w_closeness_test = []\n",
    "features_twicw_test = []\n",
    "features_tfidf_test = []\n",
    "\n",
    "for i, graph in enumerate(all_graphs_test):\n",
    "    \n",
    "    # filter out the terms that are not in the training set\n",
    "    terms_in_doc = [term for term in terms_by_doc_test[i] if term in all_unique_terms]\n",
    "    doc_len = len(terms_in_doc)\n",
    "    \n",
    "    my_metrics = compute_node_centrality(graph)\n",
    "    \n",
    "    feature_row_degree_test = [0]*len_all\n",
    "    feature_row_w_degree_test = [0]*len_all\n",
    "    feature_row_closeness_test = [0]*len_all\n",
    "    feature_row_w_closeness_test = [0]*len_all\n",
    "    feature_row_twicw_test = [0]*len_all\n",
    "    feature_row_tfidf_test = [0]*len_all\n",
    "\n",
    "    for term in list(set(terms_in_doc)):\n",
    "        index = all_unique_terms.index(term)\n",
    "        idf_term = idf[term]\n",
    "        denominator = (1-b+(b*(float(doc_len)/avg_len)))\n",
    "        metrics_term = [tuple[1:] for tuple in my_metrics if tuple[0]==term][0]\n",
    "        \n",
    "        # store TW-IDF values      \n",
    "        feature_row_degree_test[index] = (metrics_term[0]/denominator) * idf_term\n",
    "        feature_row_w_degree_test[index] = (metrics_term[1]/denominator) * idf_term\n",
    "        feature_row_closeness_test[index] = (metrics_term[2]/denominator) * idf_term\n",
    "        feature_row_w_closeness_test[index] = (metrics_term[3]/denominator) * idf_term\n",
    "        \n",
    "        # store TW-ICW values\n",
    "        feature_row_twicw_test[index] = (metrics_term[0]/denominator) * (math.log10((maxcol+1)/collection_degrees[term]))\n",
    "\n",
    "        # number of occurrences of word in document\n",
    "        tf = terms_in_doc.count(term)\n",
    "        # store TF-IDF value\n",
    "        feature_row_tfidf_test[index] = ((1+math.log1p(1+math.log1p(tf)))/(1-0.2+(0.2*(float(doc_len)/avg_len)))) * idf_term\n",
    "\n",
    "    features_degree_test.append(feature_row_degree_test)\n",
    "    features_w_degree_test.append(feature_row_w_degree_test)\n",
    "    features_closeness_test.append(feature_row_closeness_test)\n",
    "    features_w_closeness_test.append(feature_row_w_closeness_test)\n",
    "    features_twicw_test.append(feature_row_twicw_test)\n",
    "    features_tfidf_test.append(feature_row_tfidf_test)\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        print (i, \"documents processed\")\n",
    "\n",
    "# convert list of lists into array\n",
    "# documents as rows, unique words as columns (i.e., document-term matrix)\n",
    "testing_set_degree = numpy.array(features_degree_test)\n",
    "testing_set_w_degree = numpy.array(features_w_degree_test)\n",
    "testing_set_closeness = numpy.array(features_closeness_test)\n",
    "testing_set_w_closeness = numpy.array(features_w_closeness_test)\n",
    "testing_set_twicw = numpy.array(features_twicw_test)\n",
    "testing_set_tfidf = numpy.array(features_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'student'), (1, 'course'), (2, 'student'), (2, 'student'), (1, 'course'), (0, 'faculty'), (1, 'course'), (2, 'student'), (0, 'faculty'), (3, 'project'), (2, 'student'), (0, 'faculty'), (2, 'student'), (1, 'course'), (0, 'faculty'), (1, 'course'), (1, 'course'), (2, 'student'), (2, 'student'), (3, 'project')]\n",
      "[(1, 'student'), (1, 'student'), (0, 'faculty'), (1, 'student'), (2, 'project'), (0, 'faculty'), (0, 'faculty'), (0, 'faculty'), (1, 'student'), (3, 'course'), (1, 'student'), (0, 'faculty'), (1, 'student'), (1, 'student'), (0, 'faculty'), (0, 'faculty'), (0, 'faculty'), (1, 'student'), (0, 'faculty'), (1, 'student')]\n",
      "\n",
      "training LinearSVC classifiers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/acarossio/venv/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== accuracy for LinearSVC classifier ==========\n",
      "accuracy TW-IDF degree: 24.346\n",
      "accuracy TW-IDF weighted degree: 23.837\n",
      "accuracy TW-IDF closeness: 24.855\n",
      "accuracy TW-IDF weighted closeness: 25.0\n",
      "accuracy TW-ICW degree: 23.692\n",
      "accuracy TF-IDF: 25.727\n",
      "\n",
      "training LogisticRegression classifiers\n",
      "========== accuracy for LogisticRegression classifier ==========\n",
      "accuracy TW-IDF degree: 23.91\n",
      "accuracy TW-IDF weighted degree: 23.983\n",
      "accuracy TW-IDF closeness: 24.855\n",
      "accuracy TW-IDF weighted closeness: 24.855\n",
      "accuracy TW-ICW degree: 22.093\n",
      "accuracy TF-IDF: 25.073\n",
      "\n",
      "training MultinomialNB classifiers\n",
      "========== accuracy for MultinomialNB classifier ==========\n",
      "accuracy TW-IDF degree: 23.837\n",
      "accuracy TW-IDF weighted degree: 23.692\n",
      "accuracy TW-IDF closeness: 24.637\n",
      "accuracy TW-IDF weighted closeness: 24.564\n",
      "accuracy TW-ICW degree: 22.238\n",
      "accuracy TF-IDF: 23.91\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# labels #\n",
    "##########\n",
    "\n",
    "# convert labels into integers then into column array\n",
    "labels = list(labels)\n",
    "labels_int = [0] * len(labels)\n",
    "for j in range(len(unique_labels)):\n",
    "    index_temp = [i for i in range(len(labels)) if labels[i]==unique_labels[j]]\n",
    "    for element in index_temp:\n",
    "        labels_int[element] = j\n",
    "        \n",
    "# convert truth into integers then into column array\n",
    "truth = list(truth)\n",
    "truth_int = [0] * len(truth)\n",
    "for j in range(len(unique_truth)):\n",
    "    index_temp = [i for i in range(len(truth)) if truth[i]==unique_truth[j]]\n",
    "    for element in index_temp:\n",
    "        truth_int[element] = j\n",
    "\n",
    "# check that coding went smoothly\n",
    "print(list(zip(truth_int,truth))[:20])\n",
    "\n",
    "truth_array = numpy.array(truth_int)\n",
    "\n",
    "# check that coding went smoothly\n",
    "print(list(zip(labels_int,labels))[:20])\n",
    "labels_array = numpy.array(labels_int)\n",
    "\n",
    "for clf in [\"LinearSVC\",\"LogisticRegression\",\"MultinomialNB\"]:\n",
    "    \n",
    "    if clf==\"LinearSVC\":\n",
    "        classifier_degree = svm.LinearSVC()\n",
    "        classifier_w_degree = svm.LinearSVC()\n",
    "        classifier_closeness = svm.LinearSVC()\n",
    "        classifier_w_closeness = svm.LinearSVC()\n",
    "        classifier_twicw = svm.LinearSVC()\n",
    "        classifier_tfidf = svm.LinearSVC()\n",
    "    elif clf==\"LogisticRegression\":\n",
    "        classifier_degree = LogisticRegression(multi_class='ovr',solver='liblinear') # we specify multi_class and solver arguments just to avoid getting a warning\n",
    "        classifier_w_degree = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "        classifier_closeness = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "        classifier_w_closeness = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "        classifier_twicw = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "        classifier_tfidf = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "    elif clf==\"MultinomialNB\":\n",
    "        classifier_degree = MultinomialNB()\n",
    "        classifier_w_degree = MultinomialNB()\n",
    "        classifier_closeness = MultinomialNB()\n",
    "        classifier_w_closeness = MultinomialNB()\n",
    "        classifier_twicw = MultinomialNB()\n",
    "        classifier_tfidf = MultinomialNB()\n",
    "    \n",
    "    ############\n",
    "    # training #\n",
    "    ############\n",
    "    \n",
    "    print(\"\\ntraining\", clf, \"classifiers\")\n",
    "    classifier_degree.fit(training_set_degree, labels_array)\n",
    "    classifier_w_degree.fit(training_set_w_degree, labels_array)\n",
    "    classifier_closeness.fit(training_set_closeness, labels_array)\n",
    "    classifier_w_closeness.fit(training_set_w_closeness, labels_array)\n",
    "    classifier_twicw.fit(training_set_tw_icw, labels_array)\n",
    "    classifier_tfidf.fit(training_set_tfidf, labels_array)\n",
    "    \n",
    "    ###########\n",
    "    # testing #\n",
    "    ###########\n",
    "    \n",
    "    # issue predictions\n",
    "    predictions_degree = classifier_degree.predict(testing_set_degree)\n",
    "    predictions_w_degree = classifier_w_degree.predict(testing_set_w_degree)\n",
    "    predictions_closeness = classifier_closeness.predict(testing_set_closeness)\n",
    "    predictions_w_closeness = classifier_w_closeness.predict(testing_set_w_closeness)\n",
    "    predictions_twicw = classifier_twicw.predict(testing_set_twicw)\n",
    "    predictions_tfidf = classifier_tfidf.predict(testing_set_tfidf)\n",
    "    \n",
    "    print('========== accuracy for', clf ,'classifier ==========')\n",
    "    print(\"accuracy TW-IDF degree:\", round(metrics.accuracy_score(truth_array,predictions_degree)*100,3))\n",
    "    print(\"accuracy TW-IDF weighted degree:\", round(metrics.accuracy_score(truth_array,predictions_w_degree)*100,3))\n",
    "    print(\"accuracy TW-IDF closeness:\", round(metrics.accuracy_score(truth_array,predictions_closeness)*100,3))\n",
    "    print(\"accuracy TW-IDF weighted closeness:\", round(metrics.accuracy_score(truth_array,predictions_w_closeness)*100,3))\n",
    "    print(\"accuracy TW-ICW degree:\", round(metrics.accuracy_score(truth_array,predictions_twicw)*100,3))\n",
    "    print(\"accuracy TF-IDF:\", round(metrics.accuracy_score(truth_array,predictions_tfidf)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most important features for each class:\n",
      "faculty: algorithm faculti teach interest research phone public associ fax professor\n",
      "student: page advisor depart interest work link resum home student graduat\n",
      "project: applic softwar relat peopl support laboratori develop faculti project group\n",
      "course: note lectur grade class exam hour homework syllabu instructor assign\n",
      "\n",
      "Less important features for each class:\n",
      "faculty: gambl reif espn gaurav greenwald css crossword tea prelim\n",
      "student: surendar bohossian verma vasken salli balloon surround raster broadband\n",
      "project: super spencer macsyma chenpo ismb crossword ipng tea judici\n",
      "course: diplom grante zhongshan cluj zahorjan extracurricular astronom unpredict backgammon\n"
     ]
    }
   ],
   "source": [
    "# show the most and less important features for each class\n",
    "my_clf = classifier_tfidf\n",
    "print(\"\\nMost important features for each class:\")\n",
    "print_top10(all_unique_terms, my_clf, unique_labels)\n",
    "print(\"\\nLess important features for each class:\")\n",
    "print_bot10(all_unique_terms, my_clf, unique_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
